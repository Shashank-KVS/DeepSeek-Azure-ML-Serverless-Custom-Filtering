# ğŸš€DeepSeek-Azure-ML-Serverless-Custom-Filtering
This repository provides a structured pipeline for deploying and managing the DeepSeek AI Model using Azure Machine Learning Model Catalog. The model is hosted on serverless compute, enabling scalable inference without the need for dedicated virtual machines.

## ğŸ”¹ Key Features

âœ”ï¸ Azure ML Model Catalog Deployment â€“ Deploy DeepSeek models seamlessly. [https://learn.microsoft.com/en-us/azure/ai-studio/how-to/deploy-models-deepseek?pivots=programming-language-python#prerequisites]
âœ”ï¸ Serverless Compute â€“ No need for persistent VMs, saving costs.
âœ”ï¸ Custom Filtering Mechanism â€“ Fine-tune model outputs beyond default pre-trained filters.
âœ”ï¸ Streaming Response Handling â€“ Process real-time AI responses for large queries.
âœ”ï¸ Error Handling & Secure API Calls â€“ Robust implementation to manage API errors.

## ğŸ“– Includes: Jupyter Notebook for step-by-step execution + Python script for automated processing.


## ğŸ’¡ Keywords: DeepSeek AI, Azure ML Model Catalog, Serverless AI Deployment, Custom Filtering, AI Model Hosting.

## ğŸ“‚ Repository Structure

- `model.ipynb` â€“ Jupyter Notebook for deploying and managing DeepSeek AI on Azure ML.
- `requirements.txt` â€“ Dependencies required to run the notebook in a custom environment.
- `.gitignore` â€“ Prevents sensitive data and unnecessary files from being committed.

## ğŸ”§ Installation & Setup

Clone the repository and install dependencies:

```bash
git clone https://github.com/YOUR_GITHUB/DeepSeek-Azure-ML-Serverless-Deployment.git
cd DeepSeek-Azure-ML-Serverless-Deployment
pip install -r requirements.txt
```

## ğŸ“Š DeepSeek AI Model Deployment Process

##### 1ï¸âƒ£ Initialize Azure ML Model â€“ Deploy the DeepSeek AI model from Azure Model Catalog.
##### 2ï¸âƒ£ Configure API Calls â€“ Connect the model to serverless compute and retrieve real-time responses.
##### 3ï¸âƒ£ Apply Custom Filters â€“ Modify the AI-generated text to fit application needs.
##### 4ï¸âƒ£ Stream Model Responses â€“ Process large outputs without waiting for full completion.

## ğŸ— Dependencies

Ensure you have the following installed before running the notebook:

`azure-ai-inference`
`azure-core`
`nbformat`
`jupyter (for running the notebook)`

## Install all dependencies using:

`pip install -r requirements.txt`

## Using Python API (without Notebook)
To execute AI inference via the Python script:

```bash
from model_script import get_ai_response
response = get_ai_response("Tell me a joke.")
print(response)
```

## ğŸ”— GitHub Repository

## ğŸ“Œ DeepSeek-Azure-ML-Serverless-Deployment

## ğŸ“¬ Contact & Contributions

For contributions, issues, or feature requests, feel free to open a pull request or raise an issue on GitHub.
